{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-NLP-Grp160.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN4itn2v3Zxh"
      },
      "source": [
        "# Twitter Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa9HTnw03coW"
      },
      "source": [
        "# **1 Import Libraries/Dataset - Adding GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh7Jsacl3lhh"
      },
      "source": [
        "# 1.1 Use GPU - Check IF GPU Available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UUyj0CfwJ-e"
      },
      "source": [
        "# Libraries For Basix Processing\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Libraries For NLTK Libraries\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Libraries For Sentence Tokenization  - Tokenizes sentences from text\n",
        "from nltk.tokenize import sent_tokenize\n",
        "# Libraries For Sentence Word Tokenization  - Tokenizes words in sentences\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Libraries For Removal of stop words from the text\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "# Libraries For Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# tensor flow related Libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tdfs\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "import seaborn as sns\n",
        "print(\"Tensor Version\",tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL0u8wtcv0JY"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI0dABNB3sW9"
      },
      "source": [
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-skDFeEm36B3"
      },
      "source": [
        "# 1.3 Import Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkrEvGrDwPTc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7YiXRf6wZW1"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYb6TFNBweW8"
      },
      "source": [
        "df = pd.read_csv('training.csv', encoding = 'latin',header=None)\n",
        "df.head()\n",
        "df.columns = ['sentiment', 'id', 'date', 'query', 'user_id', 'text']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrTmKTe_4G5n"
      },
      "source": [
        "# 2  Data Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lW93i104NN5"
      },
      "source": [
        "**Print Distribution of Sentiment Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssgHSvCu4KDi"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK-HjShi4Vv8"
      },
      "source": [
        "lab_to_sentiment = {0:\"Negative\",4:\"Positive\"}\n",
        "\n",
        "def label_decoder(label):\n",
        "  return lab_to_sentiment[label]\n",
        "\n",
        "df['class_label'] = df.sentiment.apply(lambda x:label_decoder(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjcvzQw04Jhe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdvyljJ24auT"
      },
      "source": [
        "# 2.2  Plot Bar Graph - Of Sentiment Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxO0rnYJ4djW"
      },
      "source": [
        "val_counts = df['class_label'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.bar(val_counts.index,val_counts.values)\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Value Counts\")\n",
        "plt.title(\"Sentiment Data Distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XCsxGW35yVu"
      },
      "source": [
        "# 3 Data Pre Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQS5awAp5eIV"
      },
      "source": [
        "#### Print atleast 2 Rows From Each Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM9nCb9R5XFH"
      },
      "source": [
        "print(\"================================================\")\n",
        "for index,row in df[df['sentiment']==0].head(5).iterrows():\n",
        "  print(label_decoder(row.sentiment),\"-> { \",row.text,\" }\")\n",
        "print(\"================================================\")\n",
        "for index,row in df[df['sentiment']==4].head(5).iterrows():\n",
        "  print(label_decoder(row.sentiment),\"-> { \",row.text,\" }\")\n",
        "print(\"================================================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ylL5JS5qdt"
      },
      "source": [
        "#### Remove Stop Words , Remove Special Characters - Links , Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJXHkmkW5pYj"
      },
      "source": [
        "stop_words = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMzHLwJT6B-F"
      },
      "source": [
        "def preprocess(text,stem=False):\n",
        "  text = re.sub(text_cleaning_re,' ',str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stop_words:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUW812z26IgS"
      },
      "source": [
        "df.text = df.text.apply(lambda x:preprocess(x,False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrkpYEDuwn1y"
      },
      "source": [
        "sentiments=df['sentiment'].values\n",
        "sentences=df['text'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMNpZULwrdg"
      },
      "source": [
        "sentiments[sentiments==4]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FafYjf3ywwt8"
      },
      "source": [
        "sentiments[1],sentences[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29rUV7z0w1Co"
      },
      "source": [
        "total=len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb_pu9TIw45c"
      },
      "source": [
        "split=int(0.95*total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8tcH0-0w6c7"
      },
      "source": [
        "split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfTc053jxUXB"
      },
      "source": [
        "test_sentiments=sentiments[split:]\n",
        "test_sentences=sentences[split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s32jt7kJxYQ_"
      },
      "source": [
        "batch_size=2000\n",
        "train = tf.data.Dataset.from_tensor_slices((tf.constant(sentences),tf.constant(sentiments)))\n",
        "# train = train.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train = train.cache().shuffle(total)\n",
        "train = train.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxaaLQGLxcPZ"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train))\n",
        "example_input_batch[-1], example_target_batch[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ59_Babxe-9"
      },
      "source": [
        "example_input_batch[0], example_target_batch[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrnUoVvkxm45"
      },
      "source": [
        "batch_size=1000\n",
        "test = tf.data.Dataset.from_tensor_slices((tf.constant(test_sentences),tf.constant(test_sentiments)))\n",
        "# test = test.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = test.cache().shuffle(len(test_sentences))\n",
        "test = test.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QDrWhV5xp0T"
      },
      "source": [
        "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1\", output_shape=[128],\n",
        "                           input_shape=[], dtype=tf.string, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LldeT6MF_P0X"
      },
      "source": [
        "# 4) Model-1 DNN With Regularizer and Drop Out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nDlSbdW-saM"
      },
      "source": [
        "#### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy7-b2IYxwgX"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,1)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160,return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160)))\n",
        "model.add(tf.keras.layers.Dense(160, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(30, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y651sMQLx4EW"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYt9ZAI--uZc"
      },
      "source": [
        "#### Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgrIkEBNx6UQ"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(learning_rate=0.001), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3t9aMZ9-1nF"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqyCRp-6x-Ux"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath=\"cp/sentiment_model.Grp160\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "!mkdir cp\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LSe3dCtyRth"
      },
      "source": [
        "history = model.fit(train, epochs=5,validation_data=test, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrTBiKRs-fia"
      },
      "source": [
        "#### Model Evaluation - Print Train/Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEmIitLG9NLK"
      },
      "source": [
        "print('Final training loss \\t', history.history['loss'][-1])\n",
        "print('Final training accuracy ', history.history['accuracy'][-1])\n",
        "loss=history.history['loss']\n",
        "v_loss=history.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXJ1pC_q_Y3M"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzv5LaU5_fWD"
      },
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(test_sentences, test_sentiments, verbose=0)\n",
        "print(f'Test loss for Keras ReLU : {score[0]} / Test accuracy: {score[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LowUoyft_n_T"
      },
      "source": [
        "# Visualize model history\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Basic Model ReLU training / validation accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.title(' ReLU training / validation loss values')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJyR54e1_35y"
      },
      "source": [
        "#Defining function for confusion matrix plot\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    #Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "#print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7,7))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "\n",
        "    #Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXIRstcm_6Eg"
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Predict the values from the validation dataset\n",
        "\n",
        "y_pred=model.predict_classes(test_sentences)\n",
        "y_true=np.argmax(test_sentiments)\n",
        "\n",
        "# compute the confusion matrix\n",
        "#confusion_mtx = confusion_matrix(y_true,y_pred) \n",
        "class_names=['Positive',\n",
        "'Negative']\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes = class_names, title='Confusion matrix, without Regularization')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aww9XQH-AlpW"
      },
      "source": [
        "# 5) Model-2 : DNN With Different Batch Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIOwEfcGAstC"
      },
      "source": [
        "#### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcjm7mo1BDNH"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model2 = tf.keras.Sequential()\n",
        "model2.add(hub_layer)\n",
        "model2.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,1)))\n",
        "model2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160,return_sequences=True)))\n",
        "model2.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160)))\n",
        "model2.add(tf.keras.layers.Dense(160, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Dense(30, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIF9HBwSAxLv"
      },
      "source": [
        "#### Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLV95NdGBDs2"
      },
      "source": [
        "model2.compile(optimizer = tf.optimizers.Adam(learning_rate=0.001), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwB0OcnXA0xg"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4l2jJgoBEEx"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath=\"cp/sentiment_model_2.Grp160\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "!mkdir cp\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8utbm9TLEfdv"
      },
      "source": [
        "history_m2 = model2.fit(train, batch_size=128,epochs=5,validation_data=test, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55T0iW8fA4Ig"
      },
      "source": [
        "#### Model Evaluation - Print Train/Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3c6gd97BCiz"
      },
      "source": [
        "print('Final training loss \\t', history_m2.history['loss'][-1])\n",
        "print('Final training accuracy ', history_m2.history['accuracy'][-1])\n",
        "loss=history_m2.history['loss']\n",
        "v_loss=history_m2.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbII4eThFdPd"
      },
      "source": [
        "# Generate generalization metrics\n",
        "score = model2.evaluate(test_sentences, test_sentiments, verbose=0)\n",
        "print(f'Test loss for Keras ReLU : {score[0]} / Test accuracy: {score[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azR_1SUuFoH_"
      },
      "source": [
        "# Visualize model history\n",
        "plt.plot(history_m2.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history_m2.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Basic Model ReLU training / validation accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_m2.history['loss'], label='Training loss')\n",
        "plt.plot(history_m2.history['val_loss'], label='Validation loss')\n",
        "plt.title(' ReLU training / validation loss values')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLwehKZsFy8A"
      },
      "source": [
        "# 6) Model-3 : DNN With Different Optimizer and Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWT8EqsEIwt9"
      },
      "source": [
        "#### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLKn0uCLF6WP"
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model3 = tf.keras.Sequential()\n",
        "model3.add(hub_layer)\n",
        "model3.add(tf.keras.layers.Lambda(lambda x: tf.expand_dims(x,1)))\n",
        "model3.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160,return_sequences=True)))\n",
        "model3.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(160)))\n",
        "model3.add(tf.keras.layers.Dense(160, activation='relu'))\n",
        "model3.add(tf.keras.layers.Dense(30, activation='relu'))\n",
        "model3.add(tf.keras.layers.Dense(2, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkrN8KwkIz8s"
      },
      "source": [
        "#### Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8bHE3FUGCgD"
      },
      "source": [
        "model3.compile(optimizer = tf.optimizers.RMSprop(learning_rate=0.001), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThthJXDXI2mX"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVrz84P2GbmC"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath=\"cp/sentiment_model_3.Grp160\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "!mkdir cp\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACU_pnjfGgr9"
      },
      "source": [
        "history_m3 = model3.fit(train, batch_size=128,epochs=5,validation_data=test, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T213UgHKI6ob"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfFZFaRMGou5"
      },
      "source": [
        "print('Final training loss \\t', history_m3.history['loss'][-1])\n",
        "print('Final training accuracy ', history_m3.history['accuracy'][-1])\n",
        "loss=history_m3.history['loss']\n",
        "v_loss=history_m3.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMzocyW6Gx7C"
      },
      "source": [
        "# Generate generalization metrics\n",
        "score = model3.evaluate(test_sentences, test_sentiments, verbose=0)\n",
        "print(f'Test loss for Keras ReLU : {score[0]} / Test accuracy: {score[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIX4U0jpG0La"
      },
      "source": [
        "# Visualize model history\n",
        "plt.plot(history_m3.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history_m3.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Basic Model ReLU training / validation accuracies')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history_m3.history['loss'], label='Training loss')\n",
        "plt.plot(history_m3.history['val_loss'], label='Validation loss')\n",
        "plt.title(' ReLU training / validation loss values')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jyqe4wvLfHg"
      },
      "source": [
        "# 7) Model Comparision\n",
        "\n",
        "The Model Accuracies are as FOllows:\n",
        "    \n",
        "\n",
        "   \n",
        "    \n",
        "    \n",
        "    Model 1 :\n",
        "             Train Accuracy => 88.15%\n",
        "             Train Loss => 0.2736\n",
        "             Test Accuracy => 89.05%\n",
        "             Test Loss => 0.2592\n",
        "    Model 2 :\n",
        "             Train Accuracy => 89.55%\n",
        "             Train Loss => 0.2424\n",
        "             Test Accuracy => 89.8%\n",
        "             Test Loss => 0.2114\n",
        "\n",
        "\n",
        "    Model 3 :\n",
        "             Train Accuracy => 89.91%\n",
        "             Train Loss => 0.2383\n",
        "             Test Accuracy => 90.49\n",
        "             Test Loss => 0.2179\n",
        "\n",
        "  As per the Model Statistics The Model3 Performs Better than Model 1,2.\n",
        "  i.e. The model with RmsProp, with Learning Rate 0.001, and batch size 0f 128 performs better than other 2 models."
      ]
    }
  ]
}